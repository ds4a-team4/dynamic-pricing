{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "#import torch.nn.functional as F\n",
    "#import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_cost(offer):\n",
    "    return 0.8 * offer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./lr_cellphone_C.pkl','rb') as f:\n",
    "#     # END\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./cellphones/cellphonedata.csv')\n",
    "df = data[data.price_category == 'C'].copy().reset_index(drop=True)\n",
    "df.drop(columns = ['ds','price_category'],inplace=True)\n",
    "df['base_cost'] = df.offer.apply(lambda x: base_cost(x))\n",
    "\n",
    "baseline_prices = df['olist_price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand_baseline(model, df_row, olist_price):\n",
    "    \n",
    "    year = df_row.year\n",
    "    month = df_row.month\n",
    "    dayofweek = df_row.dayofweek\n",
    "    day = df_row.day\n",
    "    olist_price = df_row.olist_price\n",
    "    freight_value = df_row.freight_value\n",
    "    competition_price = df_row.competition_price\n",
    "    stock = df_row.stock\n",
    "    black_friday = df_row.black_friday\n",
    "    carnival = df_row.carnival\n",
    "    christmas = df_row.christmas\n",
    "    friday = df_row.friday\n",
    "    mothers_day = df_row.mothers_day\n",
    "    new_year = df_row.new_year\n",
    "    others = df_row.others\n",
    "    valentines = df_row.valentines\n",
    "\n",
    "    X = np.array([year, month, dayofweek, day, olist_price, freight_value,\n",
    "                 competition_price, stock, black_friday, carnival, christmas,\n",
    "                 friday, mothers_day, new_year, others, valentines]).reshape(1,-1)\n",
    "    \n",
    "    #X = xgboost.DMatrix(X)\n",
    "                 \n",
    "    orders = model.predict(X)\n",
    "    \n",
    "    return max(orders[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for row in df.itertuples():\n",
    "    y_pred.append(demand_baseline(model, row, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = (df.olist_price + df.freight_value - df['base_cost']) * y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "914367.8923021888"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4120.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['y'])\n",
    "#sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./cellphones/cellphonedata.csv')\n",
    "data = data[data.price_category == 'C'].copy().reset_index(drop=True) \n",
    "df = data[data.price_category == 'C'].copy().reset_index(drop=True)\n",
    "df.drop(columns = ['ds','price_category'],inplace=True)\n",
    "df['base_cost'] = df.offer.apply(lambda x: base_cost(x))\n",
    "\n",
    "# cols = df.columns\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# normalized = scaler.fit_transform(df)\n",
    "\n",
    "# df = pd.DataFrame(normalized, columns=cols)\n",
    "\n",
    "df.drop(columns = ['offer'],inplace=True)\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# model = LinearRegression()\n",
    "# X, y  = df.drop(columns=['base_cost', 'y']).values, df['y'].values\n",
    "# model = model.fit(X, y)\n",
    "\n",
    "df.drop(columns=['olist_price','y'], inplace=True)\n",
    "\n",
    "# print(model.coef_)\n",
    "# print(model.intercept_)\n",
    "\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_demand(model, df_row, olist_price):\n",
    "    \n",
    "    year = df_row.year\n",
    "    month = df_row.month\n",
    "    dayofweek = df_row.dayofweek\n",
    "    day = df_row.day\n",
    "    olist_price = olist_price\n",
    "    freight_value = df_row.freight_value\n",
    "    competition_price = df_row.competition_price\n",
    "    stock = df_row.stock\n",
    "    black_friday = df_row.black_friday\n",
    "    carnival = df_row.carnival\n",
    "    christmas = df_row.christmas\n",
    "    friday = df_row.friday\n",
    "    mothers_day = df_row.mothers_day\n",
    "    new_year = df_row.new_year\n",
    "    others = df_row.others\n",
    "    valentines = df_row.valentines\n",
    "\n",
    "    X = np.array([year, month, dayofweek, day, olist_price, freight_value,\n",
    "                 competition_price, stock, black_friday, carnival, christmas,\n",
    "                 friday, mothers_day, new_year, others, valentines]).reshape(1,-1)\n",
    "    \n",
    "    #X = xgboost.DMatrix(X)\n",
    "                 \n",
    "    orders = model.predict(X)\n",
    "    \n",
    "    return max(orders[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self, model, df):\n",
    "        \n",
    "        self.model = model\n",
    "        self.data = df\n",
    "        self.N = len(self.data) - 1\n",
    "        self.reset()\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        self.t = 0\n",
    "        self.done = False\n",
    "        self.orders = 0\n",
    "        self.olist_price = 0\n",
    "        self.profits = 0\n",
    "        return [self.olist_price, self.orders] + self.data.iloc[self.t].tolist() \n",
    "    \n",
    "    def step(self, act):       \n",
    "        \n",
    "        # act = 0: stay, 1: raise, 2: lower\n",
    "        if act == 0:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.05\n",
    "        elif act == 1:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.075\n",
    "        elif act == 2:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.10\n",
    "        elif act == 3:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.125\n",
    "        elif act == 4:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.15\n",
    "        elif act == 5:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.175\n",
    "        elif act == 6:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.20\n",
    "        elif act == 7:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.225\n",
    "        elif act == 8:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.25\n",
    "        elif act == 9:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.275\n",
    "\n",
    "        # Calculate demand\n",
    "        self.orders = predict_demand(self.model, self.data.iloc[self.t], self.olist_price)        \n",
    "\n",
    "        reward = (self.olist_price + self.data['freight_value'][self.t] - self.data['base_cost'][self.t])*self.orders\n",
    "        self.profits += reward\n",
    "\n",
    "        # set next time\n",
    "        self.t += 1\n",
    "        \n",
    "        if (self.t == self.N):\n",
    "            self.done=True\n",
    "\n",
    "        return [self.olist_price, self.orders] + self.data.iloc[self.t].tolist(), reward, self.done # obs, reward, done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 2017.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 30.0,\n",
       " 25.73,\n",
       " 931.1842857142856,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 744.9474285714285]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(model,df)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_dqn(env):\n",
    "\n",
    "#whats the return?\n",
    "class Q_Network(nn.Module):\n",
    "        \n",
    "    def __init__(self,obs_len,hidden_size,actions_n):\n",
    "            \n",
    "        super(Q_Network,self).__init__()\n",
    "            \n",
    "#         self.fc_val = nn.Sequential(\n",
    "#             nn.Linear(obs_len, hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_size, hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_size, actions_n)\n",
    "#             # needs softmax?\n",
    "#         )\n",
    "        \n",
    "        self.fc_val = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features=obs_len),\n",
    "            nn.Linear(obs_len, hidden_size),            \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Linear(hidden_size, actions_n),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        h =  self.fc_val(x)\n",
    "        return (h)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(36)\n",
    "torch.manual_seed(36)\n",
    "\n",
    "hidden_size = 50\n",
    "input_size = 2 + df.shape[1]\n",
    "output_size = 10 #5\n",
    "LR = 0.001\n",
    "\n",
    "epoch_num = 2\n",
    "step_max = len(env.data) - 1\n",
    "memory_size = 320 # 200\n",
    "batch_size = 32\n",
    "gamma = 0.9 # 0.97\n",
    "\n",
    "epsilon = 1.0\n",
    "epsilon_decrease = 1e-4\n",
    "epsilon_min = 0.1\n",
    "start_reduce_epsilon = 200\n",
    "train_freq = 10\n",
    "update_q_freq = 30 #20\n",
    "show_log_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t0.954500000000005\t656\t523193.194139239\t49119545.896484375\t4.132952451705933\n",
      "2\t0.8570000000000157\t1631\t452054.30767089466\t57050927.74287109\t5.91526985168457\n",
      "861678.6864543491\n",
      "1\t0.954500000000005\t656\t512779.732925649\t47528048.55488281\t4.889711856842041\n",
      "2\t0.8570000000000157\t1631\t449802.86433315853\t56507941.50185547\t6.77707052230835\n",
      "938424.781843527\n",
      "FINISHED!!!!!!!!!!\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "stop = False\n",
    "seeds = 35\n",
    "# Params\n",
    "while stop == False:\n",
    "    \n",
    "    np.random.seed(seeds)\n",
    "    torch.manual_seed(seeds)\n",
    "\n",
    "    env = Environment(model,df)\n",
    "    env.reset()\n",
    "    \n",
    "    hidden_size = 30\n",
    "    input_size = 2 + df.shape[1]\n",
    "    output_size = 10 #5\n",
    "    LR = 0.001\n",
    "\n",
    "    epoch_num = 2\n",
    "    step_max = len(env.data) - 1\n",
    "    memory_size = 320 # 200\n",
    "    batch_size = 32\n",
    "    gamma = 0.95 # 0.97\n",
    "\n",
    "    epsilon = 1.0\n",
    "    epsilon_decrease = 1e-4\n",
    "    epsilon_min = 0.1\n",
    "    start_reduce_epsilon = 200\n",
    "    train_freq = 10\n",
    "    update_q_freq = 30 #20\n",
    "    show_log_freq = 5\n",
    "\n",
    "    # Training\n",
    "\n",
    "    memory = []\n",
    "    total_step = 0\n",
    "    total_rewards = []\n",
    "    total_losses = []\n",
    "\n",
    "    device = \"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    Q = Q_Network(input_size, hidden_size, output_size).to(device=device)\n",
    "\n",
    "    Q_ast = copy.deepcopy(Q)\n",
    "\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(list(Q.parameters()), lr=LR)\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(epoch_num):\n",
    "\n",
    "        pobs = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        total_loss = 0\n",
    "\n",
    "        while not done and step < step_max:\n",
    "\n",
    "            # select act\n",
    "\n",
    "            pact = np.random.randint(10)\n",
    "            if np.random.rand() > epsilon:\n",
    "                #whats the return value?\n",
    "                Q.eval()\n",
    "                pact = Q(torch.from_numpy(np.array(pobs, dtype=np.float32).reshape(1, -1)).to(device=device))\n",
    "                pact = np.argmax(pact.data.cpu())\n",
    "                pact = pact.numpy()\n",
    "\n",
    "            # act\n",
    "            obs, reward, done = env.step(pact)\n",
    "\n",
    "            # add memory\n",
    "\n",
    "            memory.append((pobs, pact, reward, obs, done))\n",
    "            if len(memory) > memory_size:\n",
    "                memory.pop(0)\n",
    "\n",
    "            # train or update q\n",
    "            if len(memory) == memory_size:\n",
    "                if total_step % train_freq == 0:\n",
    "                    shuffled_memory = np.random.permutation(memory)\n",
    "                    memory_idx = range(len(shuffled_memory))\n",
    "                    for i in memory_idx[::batch_size]:\n",
    "                        batch = np.array(shuffled_memory[i:i+batch_size])\n",
    "                        b_pobs = np.array(batch[:, 0].tolist(), dtype=np.float32).reshape(batch_size, -1)\n",
    "                        b_pact = np.array(batch[:, 1].tolist(), dtype=np.int32)\n",
    "                        b_reward = np.array(batch[:, 2].tolist(), dtype=np.int32)\n",
    "                        b_obs = np.array(batch[:, 3].tolist(), dtype=np.float32).reshape(batch_size, -1)\n",
    "                        b_done = np.array(batch[:, 4].tolist(), dtype=np.bool)\n",
    "\n",
    "                        Q.train()\n",
    "                        q = Q(torch.from_numpy(b_pobs).to(device=device))\n",
    "                        q_ = Q_ast(torch.from_numpy(b_obs).to(device=device))\n",
    "                        maxq = np.max(q_.data.cpu().numpy(), axis=1)\n",
    "                        target = copy.deepcopy(q.data)\n",
    "                        #import pdb; pdb.set_trace()\n",
    "\n",
    "                        for j in range(batch_size):\n",
    "                            target[j, b_pact[j]] = b_reward[j]+gamma*maxq[j]*(not b_done[j])\n",
    "                        Q.zero_grad()\n",
    "                        loss = loss_function(q, target)\n",
    "                        total_loss += loss.data.item()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                if total_step % update_q_freq == 0:\n",
    "                    Q_ast = copy.deepcopy(Q)\n",
    "\n",
    "                # epsilon\n",
    "                if epsilon > epsilon_min and total_step > start_reduce_epsilon:\n",
    "                    epsilon -= epsilon_decrease\n",
    "\n",
    "                # next step\n",
    "                total_reward += reward\n",
    "                pobs = obs\n",
    "                step += 1\n",
    "                total_step += 1\n",
    "\n",
    "            total_rewards.append(total_reward)\n",
    "            total_losses.append(total_loss)\n",
    "\n",
    "            #if (epoch+1) % show_log_freq == 0:\n",
    "            if done or step == step_max:  \n",
    "                log_reward = sum(total_rewards[((epoch+1)-show_log_freq):])/show_log_freq\n",
    "                log_loss = sum(total_losses[((epoch+1)-show_log_freq):])/show_log_freq\n",
    "                elapsed_time = time.time()-start\n",
    "                print('\\t'.join(map(str, [epoch+1, epsilon, total_step, log_reward, log_loss, elapsed_time])))\n",
    "                start = time.time()\n",
    "\n",
    "\n",
    "#     test_env = Environment(model,df)\n",
    "#     test_acts=[]\n",
    "#     test_rewards = []\n",
    "#     pobs = test_env.reset()\n",
    "#     profits_2 = 0\n",
    "#     pact_history = []\n",
    "#     done = False\n",
    "#     while not done:\n",
    "#         Q.eval()\n",
    "#         pact = Q(torch.from_numpy(np.array(pobs, dtype=np.float32).reshape(1, -1)).to(device=device))\n",
    "#         pact = np.argmax(pact.data.cpu())\n",
    "#         pact_history.append(pact)\n",
    "#         test_acts.append(pact.item())\n",
    "\n",
    "#         obs, reward, done = test_env.step(pact.numpy())\n",
    "#         test_rewards.append(reward)\n",
    "#         profits_2 += reward\n",
    "#         pobs = obs\n",
    "\n",
    "#     test_profits = test_env.profits\n",
    "    \n",
    "    test_env = Environment(model,df)\n",
    "    test_acts=[]\n",
    "    test_rewards = []\n",
    "    orders = []\n",
    "    o_prices = []\n",
    "    pobs = test_env.reset()\n",
    "    profits_2 = 0\n",
    "    pact_history = []\n",
    "    done = False\n",
    "    while not done:\n",
    "        Q.eval()\n",
    "        pact = Q(torch.from_numpy(np.array(pobs, dtype=np.float32).reshape(1, -1)).to(device=device))\n",
    "        pact = np.argmax(pact.data.cpu())\n",
    "        pact_history.append(pact)\n",
    "        test_acts.append(pact.item())\n",
    "\n",
    "        obs, reward, done = test_env.step(pact.numpy())\n",
    "        orders.append(obs[1])\n",
    "        o_prices.append(obs[0])\n",
    "        test_rewards.append(reward)\n",
    "        profits_2 += reward\n",
    "        pobs = obs\n",
    "\n",
    "    test_profits = test_env.profits\n",
    "    print(test_profits)\n",
    "    \n",
    "    if test_profits > sum(baseline):\n",
    "        print('FINISHED!!!!!!!!!!')\n",
    "        print(seeds)\n",
    "        stop = True\n",
    "    else:\n",
    "        seeds += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = df.iloc[:-1].copy()\n",
    "\n",
    "results['baseline_prices'] = baseline_prices[:-1]\n",
    "results['baseline_orders'] = y_pred[:-1]\n",
    "results['baseline_rewards'] = baseline[:-1]\n",
    "results['rl_prices'] = o_prices\n",
    "results['rl_orders'] = orders\n",
    "results['rl_actions'] = test_acts\n",
    "results['rl_rewards'] = test_rewards\n",
    "results['group'] = 'electronics'\n",
    "results['type'] = 'cellphones'\n",
    "results['price_range'] = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./cellphones_final_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Q.state_dict(), './Q_state.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds4a",
   "language": "python",
   "name": "ds4a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
