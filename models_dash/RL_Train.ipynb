{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "#import torch.nn.functional as F\n",
    "#import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_cost(offer):\n",
    "    return 0.8 * offer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renato/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/renato/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('./lr_cellphone_C.pkl','rb') as f:\n",
    "#     # END\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./cellphones/cellphonedata.csv')\n",
    "df = data[data.price_category == 'C'].copy().reset_index(drop=True)\n",
    "df.drop(columns = ['ds','price_category'],inplace=True)\n",
    "df['base_cost'] = df.offer.apply(lambda x: base_cost(x))\n",
    "\n",
    "baseline_prices = df['olist_price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand_baseline(model, df_row, olist_price):\n",
    "    \n",
    "    year = df_row.year\n",
    "    month = df_row.month\n",
    "    dayofweek = df_row.dayofweek\n",
    "    day = df_row.day\n",
    "    olist_price = df_row.olist_price\n",
    "    freight_value = df_row.freight_value\n",
    "    competition_price = df_row.competition_price\n",
    "    stock = df_row.stock\n",
    "    black_friday = df_row.black_friday\n",
    "    carnival = df_row.carnival\n",
    "    christmas = df_row.christmas\n",
    "    friday = df_row.friday\n",
    "    mothers_day = df_row.mothers_day\n",
    "    new_year = df_row.new_year\n",
    "    others = df_row.others\n",
    "    valentines = df_row.valentines\n",
    "\n",
    "    X = np.array([year, month, dayofweek, day, olist_price, freight_value,\n",
    "                 competition_price, stock, black_friday, carnival, christmas,\n",
    "                 friday, mothers_day, new_year, others, valentines]).reshape(1,-1)\n",
    "    \n",
    "    #X = xgboost.DMatrix(X)\n",
    "                 \n",
    "    orders = model.predict(X)\n",
    "    \n",
    "    return max(orders[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for row in df.itertuples():\n",
    "    y_pred.append(demand_baseline(model, row, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = (df.olist_price + df.freight_value - df['base_cost']) * y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "914367.8923021916"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4120.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['y'])\n",
    "#sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./cellphones/cellphonedata.csv')\n",
    "data = data[data.price_category == 'C'].copy().reset_index(drop=True) \n",
    "df = data[data.price_category == 'C'].copy().reset_index(drop=True)\n",
    "df.drop(columns = ['ds','price_category'],inplace=True)\n",
    "df['base_cost'] = df.offer.apply(lambda x: base_cost(x))\n",
    "\n",
    "# cols = df.columns\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# normalized = scaler.fit_transform(df)\n",
    "\n",
    "# df = pd.DataFrame(normalized, columns=cols)\n",
    "\n",
    "df.drop(columns = ['offer'],inplace=True)\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# model = LinearRegression()\n",
    "# X, y  = df.drop(columns=['base_cost', 'y']).values, df['y'].values\n",
    "# model = model.fit(X, y)\n",
    "\n",
    "df.drop(columns=['olist_price','y'], inplace=True)\n",
    "\n",
    "# print(model.coef_)\n",
    "# print(model.intercept_)\n",
    "\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_demand(model, df_row, olist_price):\n",
    "    \n",
    "    year = df_row.year\n",
    "    month = df_row.month\n",
    "    dayofweek = df_row.dayofweek\n",
    "    day = df_row.day\n",
    "    olist_price = olist_price\n",
    "    freight_value = df_row.freight_value\n",
    "    competition_price = df_row.competition_price\n",
    "    stock = df_row.stock\n",
    "    black_friday = df_row.black_friday\n",
    "    carnival = df_row.carnival\n",
    "    christmas = df_row.christmas\n",
    "    friday = df_row.friday\n",
    "    mothers_day = df_row.mothers_day\n",
    "    new_year = df_row.new_year\n",
    "    others = df_row.others\n",
    "    valentines = df_row.valentines\n",
    "\n",
    "    X = np.array([year, month, dayofweek, day, olist_price, freight_value,\n",
    "                 competition_price, stock, black_friday, carnival, christmas,\n",
    "                 friday, mothers_day, new_year, others, valentines]).reshape(1,-1)\n",
    "    \n",
    "    #X = xgboost.DMatrix(X)\n",
    "                 \n",
    "    orders = model.predict(X)\n",
    "    \n",
    "    return max(orders[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self, model, df):\n",
    "        \n",
    "        self.model = model\n",
    "        self.data = df\n",
    "        self.N = len(self.data) - 1\n",
    "        self.reset()\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        self.t = 0\n",
    "        self.done = False\n",
    "        self.orders = 0\n",
    "        self.olist_price = 0\n",
    "        self.profits = 0\n",
    "        return [self.olist_price, self.orders] + self.data.iloc[self.t].tolist() \n",
    "    \n",
    "    def step(self, act):       \n",
    "        \n",
    "        # act = 0: stay, 1: raise, 2: lower\n",
    "        if act == 0:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.05\n",
    "        elif act == 1:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.075\n",
    "        elif act == 2:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.10\n",
    "        elif act == 3:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.125\n",
    "        elif act == 4:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.15\n",
    "        elif act == 5:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.175\n",
    "        elif act == 6:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.20\n",
    "        elif act == 7:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.225\n",
    "        elif act == 8:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.25\n",
    "        elif act == 9:\n",
    "            self.olist_price = self.data['base_cost'][self.t] * 1.275\n",
    "\n",
    "        # Calculate demand\n",
    "        self.orders = predict_demand(self.model, self.data.iloc[self.t], self.olist_price)        \n",
    "\n",
    "        reward = (self.olist_price + self.data['freight_value'][self.t] - self.data['base_cost'][self.t])*self.orders\n",
    "        self.profits += reward\n",
    "\n",
    "        # set next time\n",
    "        self.t += 1\n",
    "        \n",
    "        if (self.t == self.N):\n",
    "            self.done=True\n",
    "\n",
    "        return [self.olist_price, self.orders] + self.data.iloc[self.t].tolist(), reward, self.done # obs, reward, done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 2017.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 30.0,\n",
       " 25.73,\n",
       " 931.1842857142856,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 744.9474285714285]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(model,df)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_dqn(env):\n",
    "\n",
    "#whats the return?\n",
    "class Q_Network(nn.Module):\n",
    "        \n",
    "    def __init__(self,obs_len,hidden_size,actions_n):\n",
    "            \n",
    "        super(Q_Network,self).__init__()\n",
    "            \n",
    "#         self.fc_val = nn.Sequential(\n",
    "#             nn.Linear(obs_len, hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_size, hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_size, actions_n)\n",
    "#             # needs softmax?\n",
    "#         )\n",
    "        \n",
    "        self.fc_val = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features=obs_len),\n",
    "            nn.Linear(obs_len, hidden_size),            \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Linear(hidden_size, actions_n),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        h =  self.fc_val(x)\n",
    "        return (h)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(36)\n",
    "torch.manual_seed(36)\n",
    "\n",
    "hidden_size = 50\n",
    "input_size = 2 + df.shape[1]\n",
    "output_size = 10 #5\n",
    "LR = 0.001\n",
    "\n",
    "epoch_num = 2\n",
    "step_max = len(env.data) - 1\n",
    "memory_size = 320 # 200\n",
    "batch_size = 32\n",
    "gamma = 0.9 # 0.97\n",
    "\n",
    "epsilon = 1.0\n",
    "epsilon_decrease = 1e-4\n",
    "epsilon_min = 0.1\n",
    "start_reduce_epsilon = 200\n",
    "train_freq = 10\n",
    "update_q_freq = 30 #20\n",
    "show_log_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t0.954500000000005\t656\t512081.8335665654\t47281618.140039064\t5.454712390899658\n",
      "2\t0.8570000000000157\t1631\t447964.41372975084\t54922498.262304686\t9.542678356170654\n"
     ]
    }
   ],
   "source": [
    "memory = []\n",
    "total_step = 0\n",
    "total_rewards = []\n",
    "total_losses = []\n",
    "\n",
    "device = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "Q = Q_Network(input_size, hidden_size, output_size).to(device=device)\n",
    "\n",
    "Q_ast = copy.deepcopy(Q)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(Q.parameters()), lr=LR)\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(epoch_num):\n",
    "\n",
    "    pobs = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    while not done and step < step_max:\n",
    "\n",
    "        # select act\n",
    "\n",
    "        pact = np.random.randint(10)\n",
    "        if np.random.rand() > epsilon:\n",
    "            #whats the return value?\n",
    "            Q.eval()\n",
    "            pact = Q(torch.from_numpy(np.array(pobs, dtype=np.float32).reshape(1, -1)).to(device=device))\n",
    "            pact = np.argmax(pact.data.cpu())\n",
    "            pact = pact.numpy()\n",
    "        \n",
    "        # act\n",
    "        obs, reward, done = env.step(pact)\n",
    "\n",
    "        # add memory\n",
    "        \n",
    "        memory.append((pobs, pact, reward, obs, done))\n",
    "        if len(memory) > memory_size:\n",
    "            memory.pop(0)\n",
    "\n",
    "        # train or update q\n",
    "        if len(memory) == memory_size:\n",
    "            if total_step % train_freq == 0:\n",
    "                shuffled_memory = np.random.permutation(memory)\n",
    "                memory_idx = range(len(shuffled_memory))\n",
    "                for i in memory_idx[::batch_size]:\n",
    "                    batch = np.array(shuffled_memory[i:i+batch_size])\n",
    "                    b_pobs = np.array(batch[:, 0].tolist(), dtype=np.float32).reshape(batch_size, -1)\n",
    "                    b_pact = np.array(batch[:, 1].tolist(), dtype=np.int32)\n",
    "                    b_reward = np.array(batch[:, 2].tolist(), dtype=np.int32)\n",
    "                    b_obs = np.array(batch[:, 3].tolist(), dtype=np.float32).reshape(batch_size, -1)\n",
    "                    b_done = np.array(batch[:, 4].tolist(), dtype=np.bool)\n",
    "                    \n",
    "                    Q.train()\n",
    "                    q = Q(torch.from_numpy(b_pobs).to(device=device))\n",
    "                    q_ = Q_ast(torch.from_numpy(b_obs).to(device=device))\n",
    "                    maxq = np.max(q_.data.cpu().numpy(), axis=1)\n",
    "                    target = copy.deepcopy(q.data)\n",
    "                    #import pdb; pdb.set_trace()\n",
    "\n",
    "                    for j in range(batch_size):\n",
    "                        target[j, b_pact[j]] = b_reward[j]+gamma*maxq[j]*(not b_done[j])\n",
    "                    Q.zero_grad()\n",
    "                    loss = loss_function(q, target)\n",
    "                    total_loss += loss.data.item()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "            if total_step % update_q_freq == 0:\n",
    "                Q_ast = copy.deepcopy(Q)\n",
    "                \n",
    "            # epsilon\n",
    "            if epsilon > epsilon_min and total_step > start_reduce_epsilon:\n",
    "                epsilon -= epsilon_decrease\n",
    "\n",
    "            # next step\n",
    "            total_reward += reward\n",
    "            pobs = obs\n",
    "            step += 1\n",
    "            total_step += 1\n",
    "\n",
    "        total_rewards.append(total_reward)\n",
    "        total_losses.append(total_loss)\n",
    "\n",
    "        #if (epoch+1) % show_log_freq == 0:\n",
    "        if done or step == step_max:  \n",
    "            log_reward = sum(total_rewards[((epoch+1)-show_log_freq):])/show_log_freq\n",
    "            log_loss = sum(total_losses[((epoch+1)-show_log_freq):])/show_log_freq\n",
    "            elapsed_time = time.time()-start\n",
    "            print('\\t'.join(map(str, [epoch+1, epsilon, total_step, log_reward, log_loss, elapsed_time])))\n",
    "            start = time.time()\n",
    "            \n",
    "#return Q, total_losses, total_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Q.state_dict(), './Q_state.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniconda",
   "language": "python",
   "name": "miniconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
